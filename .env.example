# UDAE Environment Configuration
# Copy this to .env and fill in your actual values
# See LLM_PROVIDER_CONFIG.md for detailed provider configuration

# ============================================
# OpenMetadata Configuration
# ============================================
OM_URL=http://localhost:8585/api
OM_TOKEN=

# Get token from:
# 1. Login to http://localhost:8585 (admin/admin)
# 2. Settings → Bots → Create Bot
# 3. Copy JWT token here

# ============================================
# LLM Provider Configuration
# ============================================

# METHOD 1: Generic Configuration (Recommended)
# Works with any OpenAI-compatible provider
LLM_PROVIDER=anthropic
LLM_BASE_URL=https://api.anthropic.com/v1
LLM_API_KEY=
LLM_MODEL=claude-sonnet-4-5-20250929
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=4096

# METHOD 2: Direct Provider Keys (Legacy, still supported)
# ANTHROPIC_API_KEY=
# OPENAI_API_KEY=

# Enterprise Proxy Example:
# LLM_PROVIDER=anthropic
# LLM_BASE_URL=https://llm-proxy.company.com/v1
# LLM_API_KEY=your-company-token
# LLM_MODEL=claude-sonnet-4-5-20250929

# Self-Hosted Example (Ollama):
# LLM_PROVIDER=ollama
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_API_KEY=not-required
# LLM_MODEL=llama3.3:70b

# ============================================
# Output Configuration
# ============================================
OUTPUT_DIR=./schemas

# ============================================
# Cube.js Configuration (for text-to-query)
# ============================================
CUBEJS_URL=http://localhost:4000
CUBEJS_API_SECRET=mysecretkey123

# ============================================
# Optional: Advanced Settings
# ============================================
# LOG_LEVEL=INFO
# BATCH_DELAY=0.1
